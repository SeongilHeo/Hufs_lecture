{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6. KNN - Handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Double Click here to edit this cell***\n",
    "\n",
    "- Name: 허성일\n",
    "- Student ID: 201603727\n",
    "- Submission date: 2020.06.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 1797 handwritten digits of size 8x8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with some handwritten images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is 0\n",
      "Data is :\n",
      "\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "k = 0\n",
    "print('Target is {}'.format(digits.target[k]))\n",
    "print('Data is :\\n')\n",
    "print(digits.data[k].reshape(8,8))\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[k]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (30 pts)\n",
    "\n",
    "- We want to classify handwritten digits using **k nearest neighbor classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1\n",
    "\n",
    "- import whatever you need\n",
    "- don't modify the random number seed\n",
    "- you must set \"np.random.seed(0)\"\" before you do \"train_test_split\"\n",
    "- Split the data into training dataset (2/3 of the total data), test dataset(1/3 of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "digits_df = pd.DataFrame(digits.data, columns = digits.feature_names)\n",
    "digits_target_df = pd.DataFrame(digits.target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2\n",
    "\n",
    "- Use sklearn k nearest neighbor classifier to classify digits\n",
    "- Print confusion matrix, classification report, accuracy\n",
    "- This homework will be graded based on **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix : \n",
      "\n",
      "[[49  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 61  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 62  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 50  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 63  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 67  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 56  0  0]\n",
      " [ 0  2  0  1  0  0  0  0 64  0]\n",
      " [ 0  0  0  3  0  1  0  0  0 58]]\n",
      "\n",
      "\n",
      "classification_report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.97      1.00      0.98        61\n",
      "           2       1.00      1.00      1.00        62\n",
      "           3       0.93      1.00      0.96        55\n",
      "           4       1.00      1.00      1.00        50\n",
      "           5       0.98      0.97      0.98        65\n",
      "           6       0.99      1.00      0.99        67\n",
      "           7       1.00      1.00      1.00        56\n",
      "           8       1.00      0.96      0.98        67\n",
      "           9       0.98      0.94      0.96        62\n",
      "\n",
      "    accuracy                           0.98       594\n",
      "   macro avg       0.99      0.99      0.99       594\n",
      "weighted avg       0.99      0.98      0.98       594\n",
      "\n",
      "Average accuracy = 98.48%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "k_max_score = [0,0]#optimize_k, score\n",
    "for k in range(1,30):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    if score > k_max_score[1]:\n",
    "        k_max_score = [k,score]\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=k_max_score[0])\n",
    "neigh.fit(X_train, y_train)\n",
    "predict = neigh.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test,predict)\n",
    "cr = classification_report(y_test,predict)\n",
    "accuracy = k_max_score[1]\n",
    "\n",
    "print('confusion matrix : \\n')\n",
    "print(cm)\n",
    "print('\\n\\nclassification_report : \\n')\n",
    "print(cr)\n",
    "print('Average accuracy = {:.2f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My result:\n",
    "```\n",
    "confusion matrix : \n",
    "\n",
    "[[49  0  0  0  0  0  0  0  0  0]\n",
    " [ 0 61  0  0  0  0  0  0  0  0]\n",
    " [ 0  0 62  0  0  0  0  0  0  0]\n",
    " [ 0  0  0 55  0  0  0  0  0  0]\n",
    " [ 0  0  0  0 50  0  0  0  0  0]\n",
    " [ 0  0  0  0  0 63  1  0  0  1]\n",
    " [ 0  0  0  0  0  0 67  0  0  0]\n",
    " [ 0  0  0  0  0  0  0 56  0  0]\n",
    " [ 0  2  0  1  0  0  0  0 64  0]\n",
    " [ 0  0  0  3  0  1  0  0  0 58]]\n",
    "\n",
    "\n",
    "classification_report : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        49\n",
    "           1       0.97      1.00      0.98        61\n",
    "           2       1.00      1.00      1.00        62\n",
    "           3       0.93      1.00      0.96        55\n",
    "           4       1.00      1.00      1.00        50\n",
    "           5       0.98      0.97      0.98        65\n",
    "           6       0.99      1.00      0.99        67\n",
    "           7       1.00      1.00      1.00        56\n",
    "           8       1.00      0.96      0.98        67\n",
    "           9       0.98      0.94      0.96        62\n",
    "\n",
    "    accuracy                           0.98       594\n",
    "   macro avg       0.99      0.99      0.99       594\n",
    "weighted avg       0.99      0.98      0.98       594\n",
    "\n",
    "Average accuracy = 98.48%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-Art of MNIST classification: 99.79%\n",
    "\n",
    "- https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "- MNIST dataset is much bigger dataset: 60,000 training images and 10,000 testing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (30 pts)\n",
    "\n",
    "- If you choose any hyperparameters and you did any transformation in your data, justify your choice and transformation.\n",
    "- The justification must be code, data, or plotted images, **not your guess!!!**\n",
    "- This must be a longer code. \n",
    "- Use plotted image whenever possible.\n",
    "- You may add as many cells as you want.\n",
    "- To add a cell, insert->insert cell or click '+' button above in the notebook.\n",
    "- you must set \"np.random.seed(0)\"\" before you do \"train_test_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CELL\n",
    "# you must set \"np.random.seed(0)\"\" before you do \"train_test_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "np.random.seed(0)\n",
    "digits_df = pd.DataFrame(digits.data, columns = digits.feature_names)\n",
    "digits_target_df = pd.DataFrame(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca dim = 1, Average accuracy = 34.85%, k =23\n",
      "pca dim = 2, Average accuracy = 63.80%, k =25\n",
      "pca dim = 3, Average accuracy = 74.41%, k =26\n",
      "pca dim = 4, Average accuracy = 85.35%, k =5\n",
      "pca dim = 5, Average accuracy = 90.74%, k =4\n",
      "pca dim = 6, Average accuracy = 92.26%, k =3\n",
      "pca dim = 7, Average accuracy = 95.96%, k =4\n",
      "pca dim = 8, Average accuracy = 96.30%, k =4\n",
      "pca dim = 9, Average accuracy = 97.47%, k =3\n",
      "pca dim = 10, Average accuracy = 97.81%, k =3\n",
      "pca dim = 11, Average accuracy = 97.98%, k =1\n",
      "pca dim = 12, Average accuracy = 97.98%, k =1\n",
      "pca dim = 13, Average accuracy = 97.98%, k =3\n",
      "pca dim = 14, Average accuracy = 97.98%, k =1\n",
      "pca dim = 15, Average accuracy = 98.15%, k =1\n",
      "pca dim = 16, Average accuracy = 98.32%, k =3\n",
      "pca dim = 17, Average accuracy = 98.32%, k =1\n",
      "pca dim = 18, Average accuracy = 98.15%, k =1\n",
      "pca dim = 19, Average accuracy = 98.32%, k =3\n",
      "pca dim = 20, Average accuracy = 98.48%, k =1\n",
      "pca dim = 21, Average accuracy = 98.48%, k =1\n",
      "pca dim = 22, Average accuracy = 98.48%, k =1\n",
      "pca dim = 23, Average accuracy = 98.48%, k =1\n",
      "pca dim = 24, Average accuracy = 98.32%, k =1\n",
      "pca dim = 25, Average accuracy = 98.32%, k =1\n",
      "pca dim = 26, Average accuracy = 98.32%, k =1\n",
      "pca dim = 27, Average accuracy = 98.32%, k =1\n",
      "pca dim = 28, Average accuracy = 98.48%, k =1\n",
      "pca dim = 29, Average accuracy = 98.32%, k =1\n",
      "pca dim = 30, Average accuracy = 98.48%, k =1\n",
      "pca dim = 31, Average accuracy = 98.48%, k =1\n",
      "pca dim = 32, Average accuracy = 98.48%, k =1\n",
      "pca dim = 33, Average accuracy = 98.32%, k =1\n",
      "pca dim = 34, Average accuracy = 98.32%, k =1\n",
      "pca dim = 35, Average accuracy = 98.32%, k =1\n",
      "pca dim = 36, Average accuracy = 98.32%, k =1\n",
      "pca dim = 37, Average accuracy = 98.32%, k =1\n",
      "pca dim = 38, Average accuracy = 98.48%, k =1\n",
      "pca dim = 39, Average accuracy = 98.48%, k =1\n",
      "pca dim = 40, Average accuracy = 98.48%, k =1\n",
      "pca dim = 41, Average accuracy = 98.32%, k =1\n",
      "pca dim = 42, Average accuracy = 98.48%, k =1\n",
      "pca dim = 43, Average accuracy = 98.48%, k =1\n",
      "pca dim = 44, Average accuracy = 98.48%, k =1\n",
      "pca dim = 45, Average accuracy = 98.48%, k =1\n",
      "pca dim = 46, Average accuracy = 98.48%, k =1\n",
      "pca dim = 47, Average accuracy = 98.48%, k =1\n",
      "pca dim = 48, Average accuracy = 98.48%, k =1\n",
      "pca dim = 49, Average accuracy = 98.48%, k =1\n",
      "pca dim = 50, Average accuracy = 98.48%, k =1\n",
      "pca dim = 51, Average accuracy = 98.48%, k =1\n",
      "pca dim = 52, Average accuracy = 98.48%, k =1\n",
      "pca dim = 53, Average accuracy = 98.48%, k =1\n",
      "pca dim = 54, Average accuracy = 98.48%, k =1\n",
      "pca dim = 55, Average accuracy = 98.48%, k =1\n",
      "pca dim = 56, Average accuracy = 98.48%, k =1\n",
      "pca dim = 57, Average accuracy = 98.48%, k =1\n",
      "pca dim = 58, Average accuracy = 98.48%, k =1\n",
      "pca dim = 59, Average accuracy = 98.48%, k =1\n",
      "pca dim = 60, Average accuracy = 98.48%, k =1\n",
      "pca dim = 61, Average accuracy = 98.48%, k =1\n",
      "pca dim = 62, Average accuracy = 98.48%, k =1\n",
      "pca dim = 63, Average accuracy = 98.48%, k =1\n"
     ]
    }
   ],
   "source": [
    "pca_accuracy=[]\n",
    "for pc in range(1,64):\n",
    "    np.random.seed(0)\n",
    "    pca = PCA(n_components=pc)\n",
    "    pca_digits_df=pca.fit_transform(digits_df)\n",
    "    np.random.seed(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(pca_digits_df,digits.target, test_size=0.33)\n",
    "    \n",
    "    #계산\n",
    "    # YOUR CODE HERE\n",
    "    k_max_score = [0,0]#optimize_k, score\n",
    "    for k in range(1,30):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "        neigh.fit(X_train, y_train)\n",
    "        score = neigh.score(X_test, y_test)\n",
    "        if score > k_max_score[1]:\n",
    "            k_max_score = [k,score]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k_max_score[0])\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predict = neigh.predict(X_test)\n",
    "\n",
    "    accuracy = k_max_score[1]\n",
    "\n",
    "    print('pca dim = {}, Average accuracy = {:.2f}%, k ={}'.format(pc, accuracy*100,  k_max_score[0]))\n",
    "    pca_accuracy.append(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca dim = 20, Average accuracy = 98.48%, k=1\n"
     ]
    }
   ],
   "source": [
    "print(\"pca dim = {}, Average accuracy = {:.2f}%, k={}\".format(pca_accuracy.index(max(pca_accuracy))+1, max(pca_accuracy),k_max_score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 10 Average accuracy = 98.82%\n",
      "p = 20 Average accuracy = 98.82%\n",
      "p = 30 Average accuracy = 98.65%\n",
      "p = 40 Average accuracy = 98.65%\n",
      "p = 50 Average accuracy = 98.65%\n",
      "p = 60 Average accuracy = 98.82%\n",
      "p = 70 Average accuracy = 98.82%\n",
      "p = 80 Average accuracy = 98.15%\n",
      "p = 90 Average accuracy = 98.15%\n"
     ]
    }
   ],
   "source": [
    "for p in range(10,100,10):\n",
    "    np.random.seed(0)\n",
    "    tsne=TSNE(n_components = 2,  perplexity = p,learning_rate = 200)\n",
    "    new_digits_df = tsne.fit_transform(digits_df)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "    k_max_score=[0,0]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    predict = neigh.predict(X_test)\n",
    "    \n",
    "    print('p = {} Average accuracy = {:.2f}%'.format(p, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 10 Average accuracy = 98.65%\n",
      "p = 20 Average accuracy = 98.48%\n",
      "p = 30 Average accuracy = 97.64%\n",
      "p = 40 Average accuracy = 97.31%\n",
      "p = 50 Average accuracy = 97.31%\n",
      "p = 60 Average accuracy = 97.47%\n",
      "p = 70 Average accuracy = 96.80%\n",
      "p = 80 Average accuracy = 97.31%\n",
      "p = 90 Average accuracy = 96.30%\n"
     ]
    }
   ],
   "source": [
    "for p in range(10,100,10):\n",
    "    np.random.seed(0)\n",
    "    tsne=TSNE(n_components = 1,  perplexity = p,learning_rate = 200)\n",
    "    new_digits_df = tsne.fit_transform(digits_df)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "    k_max_score=[0,0]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    predict = neigh.predict(X_test)\n",
    "    \n",
    "    print('p = {} Average accuracy = {:.2f}%'.format(p, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 10 Average accuracy = 98.65%\n",
      "p = 20 Average accuracy = 98.82%\n",
      "p = 30 Average accuracy = 98.82%\n",
      "p = 40 Average accuracy = 98.82%\n",
      "p = 50 Average accuracy = 98.82%\n",
      "p = 60 Average accuracy = 98.82%\n",
      "p = 70 Average accuracy = 98.82%\n",
      "p = 80 Average accuracy = 98.82%\n",
      "p = 90 Average accuracy = 98.65%\n"
     ]
    }
   ],
   "source": [
    "for p in range(10,100,10):\n",
    "    np.random.seed(0)\n",
    "    tsne=TSNE(n_components = 3,  perplexity = p,learning_rate = 200)\n",
    "    new_digits_df = tsne.fit_transform(digits_df)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "    k_max_score=[0,0]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    predict = neigh.predict(X_test)\n",
    "    \n",
    "    print('p = {} Average accuracy = {:.2f}%'.format(p, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.65%\n",
      "lr = 200 Average accuracy = 98.65%\n",
      "lr = 300 Average accuracy = 98.15%\n",
      "lr = 400 Average accuracy = 98.15%\n",
      "lr = 500 Average accuracy = 97.47%\n",
      "lr = 600 Average accuracy = 94.28%\n",
      "lr = 700 Average accuracy = 87.21%\n",
      "lr = 800 Average accuracy = 87.37%\n",
      "lr = 900 Average accuracy = 84.68%\n"
     ]
    }
   ],
   "source": [
    "for lr in range(100,1000,100):\n",
    "    np.random.seed(0)\n",
    "    tsne=TSNE(n_components = 3,  perplexity = 10,learning_rate = lr)\n",
    "    new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    predict = neigh.predict(X_test)\n",
    "\n",
    "    print('lr = {} Average accuracy = {:.2f}%'.format(lr, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.99%\n",
      "lr = 200 Average accuracy = 98.82%\n",
      "lr = 300 Average accuracy = 98.99%\n",
      "lr = 400 Average accuracy = 98.65%\n",
      "lr = 500 Average accuracy = 97.14%\n",
      "lr = 600 Average accuracy = 95.79%\n",
      "lr = 700 Average accuracy = 91.75%\n",
      "lr = 800 Average accuracy = 88.38%\n",
      "lr = 900 Average accuracy = 84.01%\n"
     ]
    }
   ],
   "source": [
    "for lr in range(100,1000,100):\n",
    "    np.random.seed(0)\n",
    "    tsne=TSNE(n_components = 3,  perplexity = 20,learning_rate = lr)\n",
    "    new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    predict = neigh.predict(X_test)\n",
    "\n",
    "    print('lr = {} Average accuracy = {:.2f}%'.format(lr, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.99%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tsne=TSNE(n_components = 3,  perplexity = 30,learning_rate = 100)\n",
    "new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "predict = neigh.predict(X_test)\n",
    "\n",
    "print('lr = {} Average accuracy = {:.2f}%'.format(100, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.82%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tsne=TSNE(n_components = 3,  perplexity = 40,learning_rate = 100)\n",
    "new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "predict = neigh.predict(X_test)\n",
    "\n",
    "print('lr = {} Average accuracy = {:.2f}%'.format(100, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.82%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tsne=TSNE(n_components = 3,  perplexity = 50,learning_rate = 100)\n",
    "new_digits_df = tsne.fit_transform(digits_df)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "predict = neigh.predict(X_test)\n",
    "\n",
    "print('lr = {} Average accuracy = {:.2f}%'.format(100, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.82%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tsne=TSNE(n_components = 3,  perplexity = 60,learning_rate = 100)\n",
    "new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "predict = neigh.predict(X_test)\n",
    "\n",
    "print('lr = {} Average accuracy = {:.2f}%'.format(100, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 100 Average accuracy = 98.82%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tsne=TSNE(n_components = 3,  perplexity = 70,learning_rate = 100)\n",
    "new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "predict = neigh.predict(X_test)\n",
    "\n",
    "print('lr = {} Average accuracy = {:.2f}%'.format(100, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix : \n",
      "\n",
      "[[49  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 61  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 61  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 50  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 63  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 67  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 56  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 65  0]\n",
      " [ 0  0  0  1  0  0  0  0  0 61]]\n",
      "\n",
      "\n",
      "classification_report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.97      1.00      0.98        61\n",
      "           2       1.00      0.98      0.99        62\n",
      "           3       0.96      1.00      0.98        55\n",
      "           4       1.00      1.00      1.00        50\n",
      "           5       1.00      0.97      0.98        65\n",
      "           6       0.99      1.00      0.99        67\n",
      "           7       1.00      1.00      1.00        56\n",
      "           8       1.00      0.97      0.98        67\n",
      "           9       0.98      0.98      0.98        62\n",
      "\n",
      "    accuracy                           0.99       594\n",
      "   macro avg       0.99      0.99      0.99       594\n",
      "weighted avg       0.99      0.99      0.99       594\n",
      "\n",
      "Average accuracy = 98.99%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tsne=TSNE(n_components = 3,  perplexity = 20,learning_rate = 100)\n",
    "new_digits_df = tsne.fit_transform(digits.data)\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_digits_df,digits.target, test_size=0.33)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "predict = neigh.predict(X_test)\n",
    "score = neigh.score(X_test, y_test)\n",
    "\n",
    "cm = confusion_matrix(y_test,predict)\n",
    "cr = classification_report(y_test,predict)\n",
    "\n",
    "print('confusion matrix : \\n')\n",
    "print(cm)\n",
    "print('\\n\\nclassification_report : \\n')\n",
    "print(cr)\n",
    "print('Average accuracy = {:.2f}%'.format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is my result. \n",
    "\n",
    "```\n",
    "confusion matrix : \n",
    "\n",
    "[[49  0  0  0  0  0  0  0  0  0]\n",
    " [ 0 61  0  0  0  0  0  0  0  0]\n",
    " [ 0  0 61  1  0  0  0  0  0  0]\n",
    " [ 0  0  0 55  0  0  0  0  0  0]\n",
    " [ 0  0  0  0 50  0  0  0  0  0]\n",
    " [ 0  0  0  0  0 63  1  0  0  1]\n",
    " [ 0  0  0  0  0  0 67  0  0  0]\n",
    " [ 0  0  0  0  0  0  0 56  0  0]\n",
    " [ 0  2  0  0  0  0  0  0 65  0]\n",
    " [ 0  0  0  1  0  0  0  0  0 61]]\n",
    "\n",
    "\n",
    "classification_report : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        49\n",
    "           1       0.97      1.00      0.98        61\n",
    "           2       1.00      0.98      0.99        62\n",
    "           3       0.96      1.00      0.98        55\n",
    "           4       1.00      1.00      1.00        50\n",
    "           5       1.00      0.97      0.98        65\n",
    "           6       0.99      1.00      0.99        67\n",
    "           7       1.00      1.00      1.00        56\n",
    "           8       1.00      0.97      0.98        67\n",
    "           9       0.98      0.98      0.98        62\n",
    "\n",
    "    accuracy                           0.99       594\n",
    "   macro avg       0.99      0.99      0.99       594\n",
    "weighted avg       0.99      0.99      0.99       594\n",
    "\n",
    "Average accuracy = 98.99%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written justification for your hyperparameter choice and data transformation\n",
    "\n",
    "- WRITE HERE (To edit, double click this cell)\n",
    "문제1에서 64pixel로 구성된 digits data를 이웃의 수 k를 1부터 30까지 1씩 증가시키며 최적의 k값이 1이라는 것을 확인했습니다.  \n",
    "문제2에서 64pixel, 64차원의 데이터를 차원을 감소시키면서 정확도 확인했습니다.  \n",
    "먼저 pca를 이용해서 차원을 감소시킬 때마다 accuracy를 확인하야겠다 생각했습니다.  \n",
    "pca로 1차원부터 63차원 까지 감소시켰을 때 19차원에서부터 98.43으로 accuracy를 확인했습니다.  \n",
    "tsne로 차원을 감소시키기는 것은 1,2,3차원만 가능합니다.  \n",
    "2차원으로 차원을 감소시켜보았습니다.  \n",
    "tsne로 차원을 감소시킬 때 매개변수로 존재하는 여러 값 중 큰 영향력을 미칠 것이라 판단되는 perplexity와 learning rate를 변화시키면 확인해보았습니다.  \n",
    "tsne로 1,2,3차원의 learning rate의 기본값인 200일 때 perplexity값의 변화를 확인 했을 때 98.82의 결과를 확인했습니다.  \n",
    "98.82의 결과가 3차원에서 가장 많이 나와서 3차원을 기준으로 모든 차원에서 동일하게 98.82가 나온 곳의 20,60,70 이여서 10~80 범위의 learning rate를 변화시켰습니다.  \n",
    "perplexity가 20일 때 learning rate 100,300에서 98.99를 확인할 수 있었습니다.  \n",
    "perplexity가 10,20일때 learning rate이 증가할수록 감소되는 경향을 보였고 500이 넘어가면 많이 작아지는 것을 확인되어서 perplexity 30부터는 learning rate를 100일 경우로 고정을 시켜 보았습니다.  \n",
    "이후 98.99를 넘는 결과를 확인할 수 없었고 perplexity = 20, learning rate = 100, n_components = 3에서 최대 accuracy 98.99를 얻었습니다.\n",
    "이번 과제에서 random seed에 대해 많은 주의를 주셨지만 random seed를 잘 못 생각하고 다시 진행했습니다. \n",
    "그리고 처음에 split을 먼저하고 차원을 감소했을 때 아주 낮은 accuracy를 얻는 다는 것을 확인했습니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics:\n",
    "If you cheat, you will get negatgive of the total points.\n",
    "If the homework total is 22 and you cheat, you get -22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to submit\n",
    "- Run **all cells**\n",
    "- Goto \"File -> Print Preview\" (If that doesn't work, you may print ipynb file in Google Chrome print menu)\n",
    "- Print the page as pdf\n",
    "- Submit the pdf file in google classroom\n",
    "- No late homeworks accepted"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
