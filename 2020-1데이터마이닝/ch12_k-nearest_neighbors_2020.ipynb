{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12. k-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from linear_algebra import distance\n",
    "from stats import mean\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nearest neighbors classification**\n",
    "Imagine that you’re trying to predict how I’m going to vote in the next presidential election.\n",
    "- one sensible approach is to look at how my neighbors are planning to vote.\n",
    "\n",
    "Now imagine you know more about me than just geography — perhaps you know **my age, my income, how\n",
    "many kids I have, and so on.**\n",
    "- Look at my neighbors who are close to me among all those dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Very simple Model**\n",
    "- Some notion of distance\n",
    "- An assumption that points that are close to one another are similar\n",
    "- Find the k nearest labeled points and let them vote on the new output.\n",
    "    - The labels could be True and False (“is spam?” or “is poisonous?” or “would be enjoyable to watch?”)\n",
    "    - Or they could be categories, like movie ratings (G, PG, PG-13, R, NC-17).\n",
    "    - Or they could be the names of presidential candidates.\n",
    "    - Or they could be favorite programming languages\n",
    "\n",
    "<img src = \"picture/le12-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following raw_majority_vote does not consider ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_majority_vote(labels):\n",
    "    votes = Counter(labels)\n",
    "    winner, _ = votes.most_common(1)[0]\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tie-Breakers**\n",
    "- Pick one of the winners at random.\n",
    "- Weight the votes by distance and pick the weighted winner.\n",
    "- Reduce k until we find a unique winner.\n",
    "    - This is used in the following implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(labels):\n",
    "    \"\"\"assumes that labels are ordered from nearest to farthest\"\"\"\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count\n",
    "                       for count in vote_counts.values()\n",
    "                       if count == winner_count])\n",
    "    if num_winners == 1:\n",
    "        return winner # unique winner, so return it\n",
    "    else:\n",
    "        return majority_vote(labels[:-1]) # try again without the farthest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on the above implementation: If the farthest is more than one, they should be removed all at once. In this\n",
    "case, there might be no decision!\n",
    "\n",
    "The following knn_classify implementation is partially wrong, too. It doesn't consider k-nearest in tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(k, labeled_points, new_point):\n",
    "    \"\"\"each labeled point should be a pair (point, label)\"\"\"\n",
    "    \n",
    "    # order the labeled points from nearest to farthest\n",
    "    by_distance = sorted(labeled_points,\n",
    "                         key=lambda point_label: distance(point_label[0], new_point))\n",
    "    \n",
    "    # find the labels for the k closest\n",
    "    k_nearest_labels = [label for _, label in by_distance[:k]]\n",
    "    \n",
    "    # and let them vote\n",
    "    return majority_vote(k_nearest_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example: Favorite Languages**\n",
    "The VP of Community Engagement wants to know if we can use these results to predict the favorite\n",
    "programming languages for places that weren’t part of our survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cities = [(-86.75,33.5666666666667,'Python'),(-88.25,30.6833333333333,'Python'),(-112.01666\n",
    "cities = [([longitude, latitude], language) for longitude, latitude, language in cities]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Terminology:**\n",
    "- k is a **hyperparameter**, which we choose and experiment with.\n",
    "- Correctness based on **\"Leave-one-out cross validation\"** (one is test data, and the others are training\n",
    "data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# try several different values for k\n",
    "for k in [1, 3, 5, 7]:\n",
    "    num_correct = 0\n",
    "    \n",
    "    for location, actual_language in cities:\n",
    "        other_cities = [other_city\n",
    "                        for other_city in cities\n",
    "                        if other_city != (location, actual_language)]\n",
    "        \n",
    "    predicted_language = knn_classify(k, other_cities, location)\n",
    "    \n",
    "    if predicted_language == actual_language:\n",
    "        num_correct += 1\n",
    "        \n",
    "    print(k, \"neighbor[s]:\", num_correct, \"correct out of\", len(cities))\n",
    "``` \n",
    "1 neighbor[s]: 40 correct out of 75  \n",
    "3 neighbor[s]: 44 correct out of 75  \n",
    "5 neighbor[s]: 41 correct out of 75  \n",
    "7 neighbor[s]: 35 correct out of 75      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 3-nearest neighbors performs the best, giving the correct result about 59% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_borders(plt, color='0.8'):\n",
    "    pass\n",
    "def plot_cities():\n",
    "    # key is language, value is pair (longitudes, latitudes)\n",
    "    plots = { \"Java\" : ([], []), \"Python\" : ([], []), \"R\" : ([], []) }\n",
    "    \n",
    "    # we want each language to have a different marker and color\n",
    "    markers = { \"Java\" : \"o\", \"Python\" : \"s\", \"R\" : \"^\" }\n",
    "    colors = { \"Java\" : \"r\", \"Python\" : \"b\", \"R\" : \"g\" }\n",
    "    \n",
    "    for (longitude, latitude), language in cities:\n",
    "        plots[language][0].append(longitude)\n",
    "        plots[language][1].append(latitude)\n",
    "        \n",
    "    # create a scatter series for each language\n",
    "    for language, (x, y) in plots.items():\n",
    "        plt.scatter(x, y, color=colors[language], marker=markers[language],\n",
    "                    label=language, zorder=10)\n",
    "        \n",
    "    plot_state_borders(plt) # assume we have a function that does this\n",
    "    \n",
    "    plt.legend(loc=0) # let matplotlib choose the location\n",
    "    plt.axis([-130,-60,20,55]) # set the axes\n",
    "    plt.title(\"Favorite Programming Languages\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "plot_cities()\n",
    "```\n",
    "<img src = \"picture/le12-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification regions**\n",
    "Look at what regions would get classified to which languages under each nearest neighbors scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_plot_grid(k=1):\n",
    "    plots = { \"Java\" : ([], []), \"Python\" : ([], []), \"R\" : ([], []) }\n",
    "    markers = { \"Java\" : \"o\", \"Python\" : \"s\", \"R\" : \"^\" }\n",
    "    colors = { \"Java\" : \"r\", \"Python\" : \"b\", \"R\" : \"g\" }\n",
    "\n",
    "    for longitude in range(-130, -60):\n",
    "        for latitude in range(20, 55):\n",
    "            predicted_language = knn_classify(k, cities, [longitude, latitude])\n",
    "            plots[predicted_language][0].append(longitude)\n",
    "            plots[predicted_language][1].append(latitude)\n",
    "\n",
    "        # create a scatter series for each language\n",
    "        for language, (x, y) in plots.items():\n",
    "            plt.scatter(x, y, color=colors[language], marker=markers[language],\n",
    "                        label=language, zorder=0)\n",
    "\n",
    "    plot_state_borders(plt, color='black') # assume we have a function that does this\n",
    "\n",
    "    plt.legend(loc=0) # let matplotlib choose the location\n",
    "    plt.axis([-130,-60,20,55]) # set the axes\n",
    "    plt.title(str(k) + \"-Nearest Neighbor Programming Languages\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn_classify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-deecf2cbc5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassify_and_plot_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-e4cb7496302e>\u001b[0m in \u001b[0;36mclassify_and_plot_grid\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlongitude\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m55\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mpredicted_language\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mplots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_language\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mplots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_language\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'knn_classify' is not defined"
     ]
    }
   ],
   "source": [
    "classify_and_plot_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn_classify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9ed119457b24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassify_and_plot_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-e4cb7496302e>\u001b[0m in \u001b[0;36mclassify_and_plot_grid\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlongitude\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m55\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mpredicted_language\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mplots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_language\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mplots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_language\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'knn_classify' is not defined"
     ]
    }
   ],
   "source": [
    "classify_and_plot_grid(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Curse of Dimensionality**\n",
    "- k-nearest neighbors runs into trouble in higher dimensions thanks to the “curse of dimensionality,” which\n",
    "boils down to the fact that high-dimensional spaces are vast.\n",
    "- Points in high-dimensional spaces tend not to be close to one another at all.\n",
    "- One way to see this is by randomly generating pairs of points in the d-dimensional “unit cube” in a variety\n",
    "of dimensions, and calculating the distances between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Throw 50 random numbers in 1, 2, 3 dimensions**\n",
    "<img src = \"picture/le12-3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point(dim):\n",
    "    return [random.random() for _ in range(dim)]\n",
    "\n",
    "def random_distances(dim, num_pairs):\n",
    "    return [distance(random_point(dim), random_point(dim))\n",
    "            for _ in range(num_pairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7.947421226228712e-06 0.3310009902894413 2.4010264196729895e-05\n",
      "6 0.18647467260473205 0.9677679968196268 0.19268530600055306\n",
      "11 0.315888574043911 1.3334395796543002 0.23689755341281116\n",
      "16 0.7209190490469604 1.6154152410436047 0.4462747600308797\n",
      "21 0.9694045860570238 1.8574960773724116 0.5218878240800003\n",
      "26 1.1698067560262715 2.0632214700056446 0.5669807013122402\n",
      "31 1.2930748713962408 2.257299829279505 0.5728414340991512\n",
      "36 1.5123637311959328 2.437670913316559 0.620413413038717\n",
      "41 1.5514668006745476 2.6039686964057926 0.5958085451703037\n",
      "46 1.6688006850159558 2.756796053135482 0.6053406392242623\n",
      "51 2.0135369208019926 2.902997336534375 0.6936061895274667\n",
      "56 2.1422705294432887 3.0461953095695335 0.7032610557548324\n",
      "61 2.2891825062886793 3.1783717877656223 0.720237486092828\n",
      "66 2.3805561409678484 3.305579571524835 0.7201630121006946\n",
      "71 2.428355816745725 3.4329484139337785 0.7073674066552892\n",
      "76 2.5356413086431617 3.558475062222762 0.7125640237195596\n",
      "81 2.682272988673655 3.669873368578009 0.7308897935388364\n",
      "86 2.8348947533212074 3.779672772114365 0.7500370863415659\n",
      "91 3.015796748953059 3.888554628876585 0.7755572537306314\n",
      "96 2.976216447967502 3.9912782735625743 0.7456800162698157\n"
     ]
    }
   ],
   "source": [
    "dimensions = range(1, 101, 5)\n",
    "\n",
    "avg_distances = []\n",
    "min_distances = []\n",
    "\n",
    "random.seed(0)\n",
    "for dim in dimensions:\n",
    "    distances = random_distances(dim, 10000) # 10,000 random pairs\n",
    "    avg_distances.append(mean(distances)) # track the average\n",
    "    min_distances.append(min(distances)) # track the minimum\n",
    "    print(dim, min(distances), mean(distances), min(distances) / mean(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Throw 10,000 distances for every dimension from 1 to 100**\n",
    "<img src = \"picture/le12-4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on indexing:**\n",
    "- For millions of data, we must index them to search efficiently.\n",
    "- Without indexing, learning take no time, prediction takes a lot of time!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **K-d Tree for Indexing**\n",
    "Step 1. for each dimension d in {1, ... , k}:\n",
    "    find a median on the dimension d\n",
    "    split data based on a median\n",
    "Step 2. repeat Step 1 until no data is found  \n",
    "<img src = \"picture/le12-5.png\">\n",
    "- You may use **a even splitter** instead of median if you want to leave **all the data points in leaf** (This is\n",
    "usually used in DB applications)\n",
    "- Note that the above diagram is equivalent to a balanced k-dimensional BST\n",
    "- We will not go deep in detail\n",
    "- However, you can think about range query, k nearest neighbor query\n",
    "- When k is large, we experience the curse of dimensionality; That is, indexing for large k is almost\n",
    "impossible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **help(neighbors.KNeighborsClassifier)**\n",
    "- Take a look at the parameters: algorithm, p, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neighbors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5c367050989c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'neighbors' is not defined"
     ]
    }
   ],
   "source": [
    "help(neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **help(neighbors.KDTree)**\n",
    "    tree.query(...) # knn query  \n",
    "    tree.query_radius(...) # range query\n",
    "\n",
    "- If you use KDTree in your real application, construct it and then pickle it (googling for python pickle and\n",
    "unpickle) (or you can use a DBMS suppoting GIS functionality)\n",
    "- Your google application may be:\n",
    "    - Find k nearest gas-stations from me : knn query\n",
    "    - Find restaurants within 5 minute walking distance : range query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "X = np.random.random((10000000, 2)) # 10 million points in 2 dimensions\n",
    "tree = KDTree(X, leaf_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dist, ind = tree.query([X[0]], k=5)\n",
    "print(ind) # indices of 3 closest neighbors\n",
    "print(dist) # distances to 3 closest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compare to Homework #2's result**\n",
    "CPU times: user 401 ms, sys: 264 ms, total: 665 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "count = tree.query_radius([X[0]], r = 0.0005, count_only=True)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5486868  0.71490509]\n",
      " [0.54875985 0.71498733]\n",
      " [0.54850997 0.71539435]\n",
      " [0.5488135  0.71518937]\n",
      " [0.54892172 0.71510044]\n",
      " [0.54897222 0.71522494]\n",
      " [0.54902884 0.71487778]\n",
      " [0.54891016 0.7152985 ]\n",
      " [0.54892252 0.71534665]]\n"
     ]
    }
   ],
   "source": [
    "print(X[tree.query_radius([X[0]], r = 0.0005)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function query_radius:\n",
      "\n",
      "query_radius(...) method of sklearn.neighbors._kd_tree.KDTree instance\n",
      "    query_radius(X, r, return_distance=False,\n",
      "    count_only=False, sort_results=False)\n",
      "    \n",
      "    query the tree for neighbors within a radius r\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        An array of points to query\n",
      "    r : distance within which neighbors are returned\n",
      "        r can be a single value, or an array of values of shape\n",
      "        x.shape[:-1] if different radii are desired for each point.\n",
      "    return_distance : bool, default=False\n",
      "        if True,  return distances to neighbors of each point\n",
      "        if False, return only neighbors\n",
      "        Note that unlike the query() method, setting return_distance=True\n",
      "        here adds to the computation time.  Not all distances need to be\n",
      "        calculated explicitly for return_distance=False.  Results are\n",
      "        not sorted by default: see ``sort_results`` keyword.\n",
      "    count_only : bool, default=False\n",
      "        if True,  return only the count of points within distance r\n",
      "        if False, return the indices of all points within distance r\n",
      "        If return_distance==True, setting count_only=True will\n",
      "        result in an error.\n",
      "    sort_results : bool, default=False\n",
      "        if True, the distances and indices will be sorted before being\n",
      "        returned.  If False, the results will not be sorted.  If\n",
      "        return_distance == False, setting sort_results = True will\n",
      "        result in an error.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    count       : if count_only == True\n",
      "    ind         : if count_only == False and return_distance == False\n",
      "    (ind, dist) : if count_only == False and return_distance == True\n",
      "    \n",
      "    count : ndarray of shape X.shape[:-1], dtype=int\n",
      "        Each entry gives the number of neighbors within a distance r of the\n",
      "        corresponding point.\n",
      "    \n",
      "    ind : ndarray of shape X.shape[:-1], dtype=object\n",
      "        Each element is a numpy integer array listing the indices of\n",
      "        neighbors of the corresponding point.  Note that unlike\n",
      "        the results of a k-neighbors query, the returned neighbors\n",
      "        are not sorted by distance by default.\n",
      "    \n",
      "    dist : ndarray of shape X.shape[:-1], dtype=object\n",
      "        Each element is a numpy double array listing the distances\n",
      "        corresponding to indices in i.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tree.query_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Use Scikit Learn KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[0.66666667 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "X = [[0], [1], [2], [3]]\n",
    "y = [0, 0, 1, 1]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "print(neigh.predict([[1.1]]))\n",
    "print(neigh.predict_proba([[0.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-427f56720256>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mneigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mneigh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cities' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = zip(*cities)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "print(neigh.predict([[-86, 33]]))\n",
    "print(neigh.predict_proba([[-86, 33]]))\n",
    "print(neigh.kneighbors([[-86, 33]], 5, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **State-of-the-Art of MNIST classification**\n",
    "\n",
    "https://en.wikipedia.org/wiki/MNIST_database (https://en.wikipedia.org/wiki/MNIST_database)\n",
    "https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "(https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
